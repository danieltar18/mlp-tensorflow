# Building MLP Neural Network(s) with TensorFlow

It was a nice journey and some would call exploration to investigate low-level and high-level possibilities of Keras/TensorFlow module. To tell the truth I used this amazing book to learn all the details and tricks to use TensorFlow for building aritifical neural networks. 

TensorFlow in Action by Thushan Ganegedara. (https://www.amazon.com/TensorFlow-2-0-Action-Thushan-Ganegedara/dp/1617298344)

I'd say it was somewhat hard to understand and develop with EagerTensor and Eagerfunctions, which are frequently used in TensorFlow's world, although the book and the comprehensive documentations on Tensorflow.Org helped me a lot. 

About this repository: It contains implementations of Multilayer Perceptron (MLP) neural networks using TensorFlow/Keras for various datasets, including MNIST, Iris, Mercedes Benz Greener Manufacturing, Boston Housing, CIFAR-10, and text classification tasks. Some model was built from scratch with low-level Keras API, some with predefined objects like Model or Sequential. It should demonstrate how to adapt MLP architectures for different types of data, including images, tabular data, and text.


## Getting Started

On Windows to use GPU support, I would recommend to install Anaconda, and TensorFlow version: '2.10.1'
https://www.anaconda.com/

1. Clone this repository:
   ```
   git clone https://github.com/danieltar18/linear-algebra.git
   ```
2. Install the required dependencies:
   ```
   pip install tensorflow==2.10.1
   ```
3. Launch Jupyter Notebook or VS code:


## Boston Housing

I made a custom MLP class with multiple hidden layers (using RelU activations) and did a KFold Gridsearch on the hyperparameters.
Before giving the raw data to the Neural Net, I implemented a Normalization layer on it. 

Features Scatter Plot:
![Boston Housing Features Visualization](boston_housing/scatter_plot_boston_housing_features.png)


I could reach a Validation RMSE: 3.45, Validation MAE: 2.59 on Validation dataset with 2 hidden layer (32, 16 neuron), 0.001 learning rate.	
![Training Loss](boston_housing/training_loss_boston.png)

https://www.kaggle.com/c/boston-housing

## CIFAR-10

If you want to deep dive in TensorFlow Datasets and how to load/read images from file to a tensor, you have to open this one. 
I read this definite tutorial on TensorFlow website: https://www.tensorflow.org/tutorials/load_data/images as best practice!
To be honest, I know that, it would be more precise to use CNN for this project, but I was very courius about the performance of a MLP network.
The best-fitting model is 2 layer deep with a dropout .2, and with a small learning rate 0.0001. 

![MLP Model](cifar_10/model.png)

On a StratifiedKfold (5) I could achive mean 38-39% accuracy, which tends to be normal/average using a MLP Neural Network.

Predictions with confidence:
![Predictions](cifar_10/predictions_cifar.png)

https://kaggle.com/competitions/cifar-10

## IRIS

Predicting on the well-known dataset Iris with the low-level Keras codes. Using tf.function, GradientTape, forward_pass and gradients.

Confusion Matrix of Predictions:
![Predictions](iris/confusion_matrix_iris.png)


https://archive.ics.uci.edu/dataset/53/iris

## Mercedes Benz Greener Manufacturing

https://kaggle.com/competitions/mercedes-benz-greener-manufacturing

## MNIST

http://yann.lecun.com/exdb/mnist/

## Text CLassification - Emotions


https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp?select=val.txt


